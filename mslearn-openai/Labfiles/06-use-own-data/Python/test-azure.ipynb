{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# https://github.com/MicrosoftLearning/mslearn-openai/blob/main/Instructions/Exercises/02-natural-language-azure-openai.md\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Add Azure OpenAI package\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # Get configuration settings\n",
    "        load_dotenv()\n",
    "        azure_oai_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "        azure_oai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "        azure_oai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "        azure_oai_deployment = os.getenv(\"AZURE_OPENAI_DEPLOYMENT\")\n",
    "\n",
    "        # Initialize the Azure OpenAI client\n",
    "        client = AzureOpenAI(\n",
    "            api_key=azure_oai_key,\n",
    "            api_version=azure_oai_api_version,\n",
    "            azure_endpoint=azure_oai_endpoint,\n",
    "        )\n",
    "\n",
    "        # Create a system message\n",
    "        system_message = \"I am a hiking enthusiast named Forest who helps people discover hikes in their area. If no area is specified, I will default to near Rainier National Park. I will then provide three suggestions for nearby hikes that vary in length. I will also share an interesting fact about the local nature on the hikes when making a recommendation.\"\n",
    "\n",
    "        # Initialize messages array\n",
    "        messages_array = [{\"role\": \"system\", \"content\": system_message}]\n",
    "\n",
    "        while True:\n",
    "            # Get input text\n",
    "            input_text = input(\"Enter the prompt (or type 'quit' to exit):\")\n",
    "            if input_text.lower() == \"quit\":\n",
    "                break\n",
    "            if len(input_text) == 0:\n",
    "                print(\"Please enter a prompt.\")\n",
    "                continue\n",
    "            print(\"\\nSending request for summary to Azure OpenAI endpoint...\\n\")\n",
    "\n",
    "            # Send request to Azure OpenAI model\n",
    "            messages_array.append({\"role\": \"user\", \"content\": input_text})\n",
    "            response = client.chat.completions.create(\n",
    "                model=azure_oai_deployment,\n",
    "                temperature=0.7,\n",
    "                max_tokens=1500,\n",
    "                messages=messages_array,\n",
    "            )\n",
    "\n",
    "            generated_text = response.choices[0].message.content\n",
    "            # Add generated text to messages array\n",
    "            messages_array.append({\"role\": \"assistant\", \"content\": generated_text})\n",
    "\n",
    "            # Print generated text\n",
    "            print(\"Summary: \" + generated_text + \"\\n\")\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# https://github.com/MicrosoftLearning/mslearn-openai/blob/main/Instructions/Exercises/06-use-own-data.md\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Add Azure OpenAI package\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # Get configuration settings\n",
    "        load_dotenv()\n",
    "        azure_oai_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "        azure_oai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "        azure_oai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "        azure_oai_deployment = os.getenv(\"AZURE_OPENAI_DEPLOYMENT\")\n",
    "        azure_search_key = os.getenv(\"AZURE_SEARCH_KEY\")\n",
    "        azure_search_endpoint = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "        azure_search_index = os.getenv(\"AZURE_SEARCH_INDEX\")\n",
    "\n",
    "        # Initialize the Azure OpenAI client\n",
    "        client = AzureOpenAI(\n",
    "            api_key=azure_oai_key,\n",
    "            api_version=azure_oai_api_version,\n",
    "            azure_endpoint=azure_oai_endpoint,\n",
    "        )\n",
    "\n",
    "        # Get the prompt\n",
    "        text = input(\"\\nEnter a question:\\n\")\n",
    "\n",
    "        # Send request to Azure OpenAI model\n",
    "        print(\"\\nSending the following request to Azure OpenAI endpoint...\\n\")\n",
    "        print(\"Request: \" + text + \"\\n\")\n",
    "\n",
    "        # Ref: https://learn.microsoft.com/en-us/azure/ai-services/openai/use-your-data-quickstart\n",
    "        response = client.chat.completions.create(\n",
    "            model=azure_oai_deployment,\n",
    "            temperature=0.5,\n",
    "            max_tokens=1000,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful travel agent.\"},\n",
    "                {\"role\": \"user\", \"content\": text},\n",
    "            ],\n",
    "            # Configure your data source\n",
    "            extra_body={\n",
    "                \"data_sources\": [\n",
    "                    {\n",
    "                        \"type\": \"azure_search\",\n",
    "                        \"parameters\": {\n",
    "                            \"authentication\": {\n",
    "                                \"type\": \"api_key\",\n",
    "                                \"key\": azure_search_key,\n",
    "                            },\n",
    "                            \"endpoint\": azure_search_endpoint,\n",
    "                            \"index_name\": azure_search_index,\n",
    "                        },\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "        )\n",
    "\n",
    "        # Flag to show citations\n",
    "        show_citations = True\n",
    "\n",
    "        # Print response\n",
    "        print(\"Response: \" + response.choices[0].message.content + \"\\n\")\n",
    "\n",
    "        if show_citations:\n",
    "            # Print citations\n",
    "            print(\"Citations: \")\n",
    "            citations = response.choices[0].message.context[\"citations\"]\n",
    "            for c in citations:\n",
    "                print(\"Title: \" + c[\"title\"] + \"\\tURL: \" + c[\"url\"])\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# https://github.com/Azure/azure-search-vector-samples/tree/main/demo-python/code/basic-vector-workflow\n",
    "# Part 1\n",
    "# Prerequisite: Azure AI Search service with basic plan (same region as Azure OpenAI resource), and Semantic ranker enabled with free plan\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SimpleField,\n",
    "    SearchFieldDataType,\n",
    "    SearchableField,\n",
    "    SearchField,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    VectorSearchProfile,\n",
    "    SemanticConfiguration,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticField,\n",
    "    SemanticSearch,\n",
    "    SearchIndex,\n",
    ")\n",
    "from azure.search.documents import SearchClient\n",
    "\n",
    "load_dotenv(override=True)\n",
    "azure_oai_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "azure_oai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "azure_oai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_oai_deployment = os.getenv(\"AZURE_OPENAI_DEPLOYMENT\")\n",
    "azure_oai_embedding_model = os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\")\n",
    "azure_search_key = (\n",
    "    AzureKeyCredential(os.getenv(\"AZURE_SEARCH_KEY\"))\n",
    "    if len(os.getenv(\"AZURE_SEARCH_KEY\")) > 0\n",
    "    else DefaultAzureCredential()\n",
    ")\n",
    "azure_search_endpoint = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "azure_search_index_vector = os.getenv(\"AZURE_SEARCH_INDEX_VECTOR\")\n",
    "\n",
    "azure_oai_client = AzureOpenAI(\n",
    "    api_key=azure_oai_key,\n",
    "    api_version=azure_oai_api_version,\n",
    "    azure_endpoint=azure_oai_endpoint,\n",
    ")\n",
    "\n",
    "input_path = os.path.join(\".\", \"text-sample.json\")\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    input_data = json.load(file)\n",
    "\n",
    "# Generate embeddings for title and content fields\n",
    "titles = [item[\"title\"] for item in input_data]\n",
    "title_response = azure_oai_client.embeddings.create(\n",
    "    input=titles,\n",
    "    model=os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\"),\n",
    ")\n",
    "title_embeddings = [item.embedding for item in title_response.data]\n",
    "content = [item[\"content\"] for item in input_data]\n",
    "content_response = azure_oai_client.embeddings.create(\n",
    "    input=content,\n",
    "    model=os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\"),\n",
    ")\n",
    "content_embeddings = [item.embedding for item in content_response.data]\n",
    "\n",
    "# Add vectorized title and content fields\n",
    "for i, item in enumerate(input_data):\n",
    "    title = item[\"title\"]\n",
    "    content = item[\"content\"]\n",
    "    item[\"titleVector\"] = title_embeddings[i]\n",
    "    item[\"contentVector\"] = content_embeddings[i]\n",
    "\n",
    "output_path = os.path.join(\".\", \"text-sample-vectors.json\")\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(input_data, f)\n",
    "\n",
    "# Initialize the Azure AI Search index client\n",
    "index_client = SearchIndexClient(\n",
    "    credential=azure_search_key,\n",
    "    endpoint=azure_search_endpoint,\n",
    ")\n",
    "\n",
    "index_fields = [\n",
    "    SimpleField(\n",
    "        name=\"id\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        key=True,\n",
    "        sortable=True,\n",
    "        filterable=True,\n",
    "        facetable=True,\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"title\",\n",
    "        type=SearchFieldDataType.String,\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"content\",\n",
    "        type=SearchFieldDataType.String,\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"category\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        filterable=True,\n",
    "    ),\n",
    "    SearchField(\n",
    "        name=\"titleVector\",\n",
    "        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "        searchable=True,\n",
    "        vector_search_dimensions=1536,\n",
    "        vector_search_profile_name=\"myHnswProfile\",\n",
    "    ),\n",
    "    SearchField(\n",
    "        name=\"contentVector\",\n",
    "        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "        searchable=True,\n",
    "        vector_search_dimensions=1536,\n",
    "        vector_search_profile_name=\"myHnswProfile\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Apply the vector search with corresponding settings\n",
    "vector_search = VectorSearch(\n",
    "    algorithms=[HnswAlgorithmConfiguration(name=\"myHnsw\")],\n",
    "    profiles=[\n",
    "        VectorSearchProfile(\n",
    "            name=\"myHnswProfile\",\n",
    "            algorithm_configuration_name=\"myHnsw\",\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Apply the semantic search with corresponding settings\n",
    "semantic_config = SemanticConfiguration(\n",
    "    name=\"mySemanticConfig\",\n",
    "    prioritized_fields=SemanticPrioritizedFields(\n",
    "        title_field=SemanticField(field_name=\"title\"),\n",
    "        keywords_fields=[SemanticField(field_name=\"category\")],\n",
    "        content_fields=[SemanticField(field_name=\"content\")],\n",
    "    ),\n",
    ")\n",
    "semantic_search = SemanticSearch(configurations=[semantic_config])\n",
    "\n",
    "# Create a new search index (contains a vector store) with related fields, and both vector search and semantic search profiles for hybrid search purpose\n",
    "index = SearchIndex(\n",
    "    name=azure_search_index_vector,\n",
    "    fields=index_fields,\n",
    "    vector_search=vector_search,\n",
    "    semantic_search=semantic_search,\n",
    ")\n",
    "result = index_client.create_or_update_index(index)\n",
    "print(f\"Index: {result.name} created/updated\\n\")\n",
    "\n",
    "# Initialize the Azure AI Search client\n",
    "search_client = SearchClient(\n",
    "    credential=azure_search_key,\n",
    "    endpoint=azure_search_endpoint,\n",
    "    index_name=azure_search_index_vector,\n",
    ")\n",
    "\n",
    "input_path = os.path.join(\".\", \"text-sample-vectors.json\")\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    input_documents = json.load(file)\n",
    "\n",
    "# Upload the prepared document (title and content fields are vectorized, while the other remains original readable text) and insert into the index\n",
    "result = search_client.upload_documents(input_documents)\n",
    "print(f\"Uploaded {len(input_documents)} records\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# https://github.com/Azure/azure-search-vector-samples/tree/main/demo-python/code/basic-vector-workflow\n",
    "# Part 2\n",
    "\n",
    "from azure.search.documents.models import VectorizedQuery\n",
    "from azure.search.documents.models import VectorFilterMode\n",
    "from azure.search.documents.models import QueryType, QueryCaptionType, QueryAnswerType\n",
    "\n",
    "# Vectorize plain text query\n",
    "query = \"tools for software development\"\n",
    "query_embedded = (\n",
    "    azure_oai_client.embeddings.create(\n",
    "        input=query,\n",
    "        model=os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\"),\n",
    "    )\n",
    "    .data[0]\n",
    "    .embedding\n",
    ")\n",
    "\n",
    "# Perform a single vector search, with a pre-filter\n",
    "query_vectorized = VectorizedQuery(\n",
    "    vector=query_embedded,\n",
    "    k_nearest_neighbors=3,\n",
    "    fields=\"contentVector\",\n",
    ")\n",
    "\n",
    "print(\"\\nPerform a single vector search...\\n\")\n",
    "results = search_client.search(\n",
    "    search_text=None,\n",
    "    vector_queries=[query_vectorized],\n",
    "    vector_filter_mode=VectorFilterMode.PRE_FILTER,\n",
    "    filter=\"category eq 'Developer Tools'\",\n",
    "    select=[\"title\", \"content\", \"category\"],\n",
    ")\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    print(f\"Content: {result['content']}\")\n",
    "    print(f\"Category: {result['category']}\\n\")\n",
    "\n",
    "# Perform a cross-field vector search, allows to query multiple vector fields at the same time\n",
    "query_vectorized = VectorizedQuery(\n",
    "    vector=query_embedded,\n",
    "    k_nearest_neighbors=3,\n",
    "    fields=\"contentVector, titleVector\",\n",
    ")\n",
    "\n",
    "print(\"\\nPerform a cross-field search...\\n\")\n",
    "results = search_client.search(\n",
    "    search_text=None,\n",
    "    vector_queries=[query_vectorized],\n",
    "    select=[\"title\", \"content\", \"category\"],\n",
    ")\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    print(f\"Content: {result['content']}\")\n",
    "    print(f\"Category: {result['category']}\\n\")\n",
    "\n",
    "# Perform a multi-vector search, allows to query multiple vector fields at the same time by passing in multiple query vectors\n",
    "query_vectorized_1 = VectorizedQuery(\n",
    "    vector=query_embedded,\n",
    "    k_nearest_neighbors=3,\n",
    "    fields=\"titleVector\",\n",
    ")\n",
    "query_vectorized_2 = VectorizedQuery(\n",
    "    vector=query_embedded,\n",
    "    k_nearest_neighbors=3,\n",
    "    fields=\"contentVector\",\n",
    ")\n",
    "\n",
    "print(\"\\nPerform a multi-vector search...\\n\")\n",
    "results = search_client.search(\n",
    "    search_text=None,\n",
    "    vector_queries=[query_vectorized_1, query_vectorized_2],\n",
    "    select=[\"title\", \"content\", \"category\"],\n",
    ")\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    print(f\"Content: {result['content']}\")\n",
    "    print(f\"Category: {result['category']}\\n\")\n",
    "\n",
    "# Perform a hybrid search (keyword + vector)\n",
    "query = \"scalable storage solution\"\n",
    "query_embedded = (\n",
    "    azure_oai_client.embeddings.create(\n",
    "        input=query,\n",
    "        model=os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\"),\n",
    "    )\n",
    "    .data[0]\n",
    "    .embedding\n",
    ")\n",
    "\n",
    "query_vectorized = VectorizedQuery(\n",
    "    vector=query_embedded,\n",
    "    k_nearest_neighbors=3,\n",
    "    fields=\"contentVector\",\n",
    ")\n",
    "\n",
    "print(\"\\nPerform a hybrid search (keyword + vector)...\\n\")\n",
    "results = search_client.search(\n",
    "    # Consider pre-processing here like rewriting the query prompt into a summary word, e.g., storage, which might be optimized for keyword or semantic sections\n",
    "    search_text=query,\n",
    "    vector_queries=[query_vectorized],\n",
    "    select=[\"title\", \"content\", \"category\"],\n",
    "    top=3,\n",
    ")\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    print(f\"Content: {result['content']}\")\n",
    "    print(f\"Category: {result['category']}\\n\")\n",
    "\n",
    "# Perform a semantic hybrid search (keyword + vector + semantic reranking)\n",
    "query = \"data analytics platform\"\n",
    "query_embedded = (\n",
    "    azure_oai_client.embeddings.create(\n",
    "        input=query,\n",
    "        model=os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\"),\n",
    "    )\n",
    "    .data[0]\n",
    "    .embedding\n",
    ")\n",
    "\n",
    "query_vectorized = VectorizedQuery(\n",
    "    vector=query_embedded,\n",
    "    k_nearest_neighbors=20,\n",
    "    fields=\"contentVector\",\n",
    "    exhaustive=True,\n",
    ")\n",
    "\n",
    "print(\"\\nPerform a semantic hybrid search (keyword + vector + semantic reranking)...\\n\")\n",
    "results = search_client.search(\n",
    "    # Consider pre-processing here like rewriting the query prompt into a summary word, e.g., analytics, which might be optimized for keyword or semantic sections\n",
    "    search_text=query,\n",
    "    vector_queries=[query_vectorized],\n",
    "    select=[\"title\", \"content\", \"category\"],\n",
    "    query_type=QueryType.SEMANTIC,\n",
    "    semantic_configuration_name=\"mySemanticConfig\",\n",
    "    query_caption=QueryCaptionType.EXTRACTIVE,\n",
    "    query_answer=QueryAnswerType.EXTRACTIVE,\n",
    "    top=3,\n",
    ")\n",
    "\n",
    "semantic_answers = results.get_answers()\n",
    "for answer in semantic_answers:\n",
    "    if answer.highlights:\n",
    "        print(f\"Semantic Answer: {answer.highlights}\")\n",
    "    else:\n",
    "        print(f\"Semantic Answer: {answer.text}\")\n",
    "    print(f\"Semantic Answer Score: {answer.score}\\n\")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Reranker Score: {result['@search.reranker_score']}\")\n",
    "    print(f\"Content: {result['content']}\")\n",
    "    print(f\"Category: {result['category']}\")\n",
    "\n",
    "    captions = result[\"@search.captions\"]\n",
    "    if captions:\n",
    "        caption = captions[0]\n",
    "        if caption.highlights:\n",
    "            print(f\"Caption: {caption.highlights}\\n\")\n",
    "        else:\n",
    "            print(f\"Caption: {caption.text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
